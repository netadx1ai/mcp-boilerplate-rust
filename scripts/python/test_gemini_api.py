#!/usr/bin/env python3
"""
Test Gemini API functionality for MCP blog generation validation
This script validates that the Gemini API is working correctly for real AI integration testing.
"""

import os
import sys
import json
import time
import requests
from typing import Optional, Dict, Any

def get_gemini_api_key() -> Optional[str]:
    """Get Gemini API key from environment variables."""
    return os.environ.get('GEMINI_API_KEY')

def generate_blog_with_gemini(
    topic: str,
    style: str = "professional",
    word_count: int = 800,
    target_audience: str = "general"
) -> Dict[str, Any]:
    """
    Generate blog content using Gemini API.
    
    Args:
        topic: Blog topic/subject
        style: Writing style (professional, casual, academic, creative)
        word_count: Target word count
        target_audience: Target audience type
        
    Returns:
        Dict containing generated content and metadata
    """
    api_key = get_gemini_api_key()
    if not api_key:
        raise ValueError("GEMINI_API_KEY environment variable not set")
    
    # Construct the prompt
    prompt = f"""Write a {style} blog post about '{topic}' targeting {target_audience} audience. 
The post should be approximately {word_count} words long.
Include proper headings, introduction, body sections, and conclusion.
Make it engaging, informative, and well-structured.
Focus on providing value to the reader."""
    
    # Prepare the request
    url = f"https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?key={api_key}"
    
    request_body = {
        "contents": [{
            "parts": [{
                "text": prompt
            }]
        }],
        "generationConfig": {
            "temperature": 0.7,
            "topK": 40,
            "topP": 0.95,
            "maxOutputTokens": min(word_count * 2, 8192),
            "candidateCount": 1
        }
    }
    
    print(f"üîÑ Generating blog post about '{topic}'...")
    start_time = time.time()
    
    try:
        response = requests.post(
            url,
            headers={"Content-Type": "application/json"},
            json=request_body,
            timeout=60
        )
        
        generation_time = time.time() - start_time
        
        if not response.ok:
            error_detail = response.text
            raise Exception(f"Gemini API error ({response.status_code}): {error_detail}")
        
        response_data = response.json()
        
        # Extract content
        content = (response_data
                  .get("candidates", [{}])[0]
                  .get("content", {})
                  .get("parts", [{}])[0]
                  .get("text", ""))
        
        if not content:
            raise Exception("No content generated by Gemini API")
        
        return {
            "content": content,
            "topic": topic,
            "style": style,
            "target_word_count": word_count,
            "target_audience": target_audience,
            "generation_time": generation_time,
            "actual_word_count": len(content.split()),
            "character_count": len(content)
        }
        
    except requests.RequestException as e:
        raise Exception(f"Request failed: {e}")
    except json.JSONDecodeError as e:
        raise Exception(f"Failed to parse response: {e}")

def validate_blog_quality(blog_data: Dict[str, Any]) -> Dict[str, Any]:
    """
    Validate the quality of generated blog content.
    
    Args:
        blog_data: Blog data dictionary from generate_blog_with_gemini
        
    Returns:
        Dict containing validation results
    """
    content = blog_data["content"]
    target_words = blog_data["target_word_count"]
    actual_words = blog_data["actual_word_count"]
    
    validation_results = {
        "passed": True,
        "issues": [],
        "metrics": {}
    }
    
    # Word count validation (¬±20% tolerance)
    word_tolerance = target_words * 0.2
    min_words = target_words - word_tolerance
    max_words = target_words + word_tolerance
    
    validation_results["metrics"]["word_count_accuracy"] = {
        "target": target_words,
        "actual": actual_words,
        "tolerance_range": f"{int(min_words)}-{int(max_words)}",
        "within_tolerance": min_words <= actual_words <= max_words
    }
    
    if not (min_words <= actual_words <= max_words):
        validation_results["passed"] = False
        validation_results["issues"].append(
            f"Word count {actual_words} outside tolerance range {int(min_words)}-{int(max_words)}"
        )
    
    # Basic structure validation
    sentences = content.count('.') + content.count('!') + content.count('?')
    paragraphs = len([p for p in content.split('\n\n') if p.strip()])
    
    validation_results["metrics"]["structure"] = {
        "sentences": sentences,
        "paragraphs": paragraphs,
        "min_length_met": len(content) >= 200
    }
    
    if sentences < 5:
        validation_results["passed"] = False
        validation_results["issues"].append("Too few sentences (minimum 5 required)")
    
    if paragraphs < 3:
        validation_results["passed"] = False
        validation_results["issues"].append("Too few paragraphs (minimum 3 required)")
    
    if len(content) < 200:
        validation_results["passed"] = False
        validation_results["issues"].append("Content too short (minimum 200 characters)")
    
    # Topic relevance (basic keyword check)
    topic_keywords = [word.lower() for word in blog_data["topic"].split() if len(word) > 3]
    content_lower = content.lower()
    
    matching_keywords = [kw for kw in topic_keywords if kw in content_lower]
    relevance_ratio = len(matching_keywords) / len(topic_keywords) if topic_keywords else 1.0
    
    validation_results["metrics"]["topic_relevance"] = {
        "topic_keywords": topic_keywords,
        "matching_keywords": matching_keywords,
        "relevance_ratio": relevance_ratio
    }
    
    if relevance_ratio < 0.3:
        validation_results["passed"] = False
        validation_results["issues"].append(f"Low topic relevance ({relevance_ratio:.2f})")
    
    return validation_results

def test_blog_generation_scenarios():
    """Test various blog generation scenarios."""
    test_scenarios = [
        {
            "name": "Technology Blog",
            "topic": "The Future of Artificial Intelligence in Software Development",
            "style": "professional",
            "word_count": 1000,
            "audience": "technical"
        },
        {
            "name": "Business Blog",
            "topic": "Sustainable Business Practices for Modern Enterprises",
            "style": "professional",
            "word_count": 800,
            "audience": "business"
        },
        {
            "name": "Health Blog",
            "topic": "Mental Health in the Digital Age",
            "style": "conversational",
            "word_count": 1200,
            "audience": "general"
        },
        {
            "name": "Casual Style Blog",
            "topic": "Remote Work Productivity Tips",
            "style": "casual",
            "word_count": 600,
            "audience": "general"
        }
    ]
    
    results = []
    
    for scenario in test_scenarios:
        print(f"\nüß™ Testing: {scenario['name']}")
        print(f"   Topic: {scenario['topic']}")
        print(f"   Style: {scenario['style']}")
        print(f"   Target: {scenario['word_count']} words")
        
        try:
            # Generate blog
            blog_data = generate_blog_with_gemini(
                topic=scenario["topic"],
                style=scenario["style"],
                word_count=scenario["word_count"],
                target_audience=scenario["audience"]
            )
            
            # Validate quality
            validation = validate_blog_quality(blog_data)
            
            # Add scenario info
            blog_data["scenario_name"] = scenario["name"]
            blog_data["validation"] = validation
            
            results.append(blog_data)
            
            # Print results
            print(f"‚úÖ Generated successfully in {blog_data['generation_time']:.2f}s")
            print(f"   Words: {blog_data['actual_word_count']} (target: {blog_data['target_word_count']})")
            print(f"   Characters: {blog_data['character_count']}")
            
            if validation["passed"]:
                print(f"‚úÖ Quality validation passed")
            else:
                print(f"‚ùå Quality issues: {', '.join(validation['issues'])}")
                
        except Exception as e:
            print(f"‚ùå Failed: {e}")
            results.append({
                "scenario_name": scenario["name"],
                "error": str(e),
                "failed": True
            })
    
    return results

def print_summary(results):
    """Print test summary."""
    print("\n" + "="*60)
    print("üî¨ GEMINI API TEST SUMMARY")
    print("="*60)
    
    total_tests = len(results)
    successful_tests = len([r for r in results if not r.get("failed", False)])
    quality_passed = len([r for r in results if not r.get("failed", False) and r.get("validation", {}).get("passed", False)])
    
    print(f"Total Tests: {total_tests}")
    print(f"Successful Generations: {successful_tests}")
    print(f"Quality Validations Passed: {quality_passed}")
    print(f"Success Rate: {(successful_tests/total_tests)*100:.1f}%")
    print(f"Quality Rate: {(quality_passed/total_tests)*100:.1f}%")
    
    if successful_tests > 0:
        avg_generation_time = sum(r.get("generation_time", 0) for r in results if not r.get("failed", False)) / successful_tests
        avg_word_count = sum(r.get("actual_word_count", 0) for r in results if not r.get("failed", False)) / successful_tests
        
        print(f"\nPerformance Metrics:")
        print(f"Average Generation Time: {avg_generation_time:.2f}s")
        print(f"Average Word Count: {avg_word_count:.0f}")
    
    print("\nDetailed Results:")
    for result in results:
        status = "‚ùå FAILED" if result.get("failed", False) else "‚úÖ SUCCESS"
        name = result.get("scenario_name", "Unknown")
        
        if result.get("failed", False):
            print(f"{status} {name}: {result.get('error', 'Unknown error')}")
        else:
            validation_status = "‚úÖ QUALITY PASS" if result.get("validation", {}).get("passed", False) else "‚ö†Ô∏è QUALITY ISSUES"
            words = result.get("actual_word_count", 0)
            time_taken = result.get("generation_time", 0)
            print(f"{status} {name}: {words} words in {time_taken:.2f}s - {validation_status}")

def main():
    """Main test execution."""
    print("üöÄ Starting Gemini API Integration Tests")
    print("="*60)
    
    # Check API key
    if not get_gemini_api_key():
        print("‚ùå GEMINI_API_KEY environment variable not set")
        print("   Please set your Gemini API key:")
        print("   export GEMINI_API_KEY='your_api_key_here'")
        sys.exit(1)
    
    print("‚úÖ GEMINI_API_KEY found")
    
    # Run tests
    try:
        results = test_blog_generation_scenarios()
        print_summary(results)
        
        # Determine exit code
        successful_tests = len([r for r in results if not r.get("failed", False)])
        quality_passed = len([r for r in results if not r.get("failed", False) and r.get("validation", {}).get("passed", False)])
        
        if successful_tests == 0:
            print("\n‚ùå All tests failed!")
            sys.exit(1)
        elif quality_passed < successful_tests:
            print(f"\n‚ö†Ô∏è Some tests had quality issues ({quality_passed}/{successful_tests} passed quality validation)")
            sys.exit(0)  # Still exit successfully since generation worked
        else:
            print(f"\nüéâ All tests passed! ({successful_tests}/{len(results)} successful)")
            sys.exit(0)
            
    except Exception as e:
        print(f"\nüí• Test execution failed: {e}")
        sys.exit(1)

if __name__ == "__main__":
    main()